---
title: "计算机网络"
date: "2022-10-16"
image: 'computerNetwork'
excerpt: '计算机网络八股'
isFeatured: true
slug: computerNetwork
category: ['computerNetwork', 'bagu']
---


# HTTP

HTTP 协议全称为 Hyper Text Transfer Protocol，即超文本传输协议。HTTP 协议主要用于客户端与服务端之间的通信，浏览器就是最常见的 HTTP 客户端。



## HTTP特点



### 一次一份

每条请求报文只能写一个URL，即以此只能写一个资源路径，造成一次只能获取一个文件。发送一个HTTP请求，需要等到HTTP响应，才能发送下一个HTTP请求。对于HTTP协议来说，我们打开网页，需要进行TCP三次握手，建立TCP连接，才正式请求，服务器会先发送HTML文件给我们，其他的文件不会发给我们，浏览器在收到HTML文件后，根据HTML里面的内容，再向服务器依次请求CSS，js等文件，整个过程都是浏览器在帮我们完成，所以用户的直接感受是只有一次请求。

### 无状态

如果每台主机访问同一服务器，服务器需要把他们的信息全部记录下来，这样服务器会崩溃，所以服务器不会把每个状态都记录下来，协议对客户端没有状态储存，对事物处理没有 "记忆能力"，这就是 HTTP 的无状态

但是目前很多功能都是有用户登录功能，如果是无状态的，用户登陆了一次，第二次访问又需要输入信息登录，所以为了保持这种状态，有了 Cookie 这种技术，在首部字段加上 cookie， 这样就能够实现保持登录状态了





## HTTP 请求

客户端向服务器发送的信息称为 请求报文，结构从上到下包括 请求行、请求头、请求体

HTTP 每条请求报文只能写一个URL， 所以只能写一个资源路径，造成每次只能获取一个文件，发送一个 HTTP 请求，需要等到HTTP 响应，才能发送下一个 HTTP 请求，

### 请求行

用于说明需要做什么， 包含三个部分--方法、资源路径、HTTP版本

* 方法： 通过方法指定对请求资源进行怎样的操作做什么样的操作（比如查询、修改等）。常见的方法有：`GET`、`POST`、`PUT`、`DELETE` 与 `HEAD`。
* 资源路径： 指定请求资源在服务器中的位置。比如 `/index.html` 表示访问服务器根目录下名字为 `index` 的 `html` 文件
* **HTTP 版本**：指定所使用的 HTTP 版本。

最常用的两个方法是 `GET` 和 `POST`

- `GET` 请求参数存放在 URL 中，而 `POST` 请求参数存储在请求体中。

参数放在 URL 中可以直接被看到，则 `GET` 请求相对 `POST` 请求更不安全。

各个浏览器对 URL 长度做了限制，比如 IE 浏览器限制 URL 的长度最大为 2KB，这就使得了 `GET` 请求传输的数据长度有了限制，而 `POST` 请求传输数据长度无限制。

- 一般 `GET` 请求用于获取数据，`POST` 请求用于新增数据。

`GET` 请求用于获取资源，不会对系统资源进行改变。`POST` 请求用于新增资源，这意味着多次请求将创建多个资源。基于这个特点，`GET` 请求可被缓存、可保留在浏览器历史记录中、浏览器回退不会产生副作用，而 `POST` 请求反之。



GET 和 POST 的区别。

- 从**缓存**的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会。
- 从**参数**的角度，GET 一般放在 URL 中，因此不安全，POST 放在请求体中，更适合传输敏感信息。
- 从**幂等性**的角度，GET 是幂等的，而 POST 不是。(幂等表示执行相同的操作，结果也是相同的)
- 从 **TCP** 的角度，GET 请求会把请求报文一次性发出去，而 POST 会分为两个 TCP 数据包，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分。(火狐浏览器除外，它的 POST 请求只发一个 TCP 包)



### 请求头

用于向服务器传递一些额外的重要信息，由字段名与字段值组成。常见的请求头包括：



|       请求头        |                             含义                             |
| :-----------------: | :----------------------------------------------------------: |
|       `Host`        |                        接收请求的域名                        |
|    `User-Agent`     |              客户端软件的名称和版本号等相关信息              |
|    `Connection`     |       设置发送响应之后 TCP 连接是否继续保持的通信选项        |
|   `Cache-Control`   |                      控制缓存的相关信息                      |
|      `Referer`      | 记录请求的来源（当通过点击超级链接进入下一个页面时，会记录上一个页面的 URL） |
|      `Accept`       |         客户端可支持的数据类型， 以 MIME 类型来表示          |
|  `Accept-Encoding`  |                    客户端可支持的编码格式                    |
|  `Accept-Language`  |                      客户端可支持的语言                      |
| `If-Modified-Since` | 用于判断资源的缓存是否有效（客户端通知服务器，本地缓存的最后变更时间） |
|   `If-None-Match`   |                  用于判断资源的缓存是否有效                  |
|       `Range`       |   用于断点续传，指定第一个字节的位置和最后一个字节的位置。   |
|      `Cookie`       |              表示请求者的身份，用于保存状态信息              |



### 请求体

用于传送客户端要发给服务器的数据，比如请求参数。

请求体与请求行和请求头不同，请求行和请求体的数据都是文本形式且格式化的，而请求体可以包含任意的二进制数据，比如文本、图片、视频等等。



## HTTP 响应



服务端向客户端发送的信息称为 响应报文，结构从上到下包括 响应行、响应头、响应体



### 响应行

用于说明对请求的处理情况，包括三个部分-- HTTP 版本、状态码、消息短语

* HTTP版本
* 状态码： 以三位数字形式描述服务器对请求的处理结果， 如200表示成功
* 消息短语： 以文本呢的形式描述服务器对请求的处理结果，如 OK 表示成功



状态码：

| 状态码 |                          含义                          |
| :----: | :----------------------------------------------------: |
| `1XX`  |        提示信息，表示请求已被成功接收，继续处理        |
| `2XX`  |              成功，表示请求被正常处理完毕              |
| `3XX`  | 重定向，资源位置发生变化，表示请求需要附加操作才能完成 |
| `4XX`  |           客户端错误，表示服务器无法处理请求           |
| `5XX`  |           服务器错误，表示服务器处理请求出错           |



一些具体的状态码及含义如下：

- `200 OK`：表示请求被正常处理。
- `204 No Content`：表示请求被正常处理，但在返回的响应报文中不含响应体内容。
- `301 Moved Permanently`：永久重定向，表示请求的资源已经被永久转移了，新的 URL 会在响应报文的 **Location** 字段中返回，浏览器将自动获取新的 URL 并发出新的请求。
- `302 Found`：临时重定向，以后还可能有变化，表示请求的资源已被临时分配了新的 URL，新的 URL 会在响应报文中的 **Location** 字段中返回，浏览器将会自动使用新的 URL 并发出新的请求。
- `304 Not Modified`：代表之前的缓存可以继续使用。
- `400 Bad Request`：一个通用差错状态码，表示请求报文中存在语法错误，客户端发生的错误。
- `401 Unauthorized`：用户未认证。
- `403 Forbidden`：表示服务器虽然收到了请求，但是拒绝提供服务，常见的原因是为没有访问权限（即用户未授权）。
- `404 Not Found`：表示请求资源不存在。
- `500 Internal Server Error`：表示服务器出现错误。
- `502 Bad Gateway`：通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- `503 Service Unavailable`：表示服务器暂时处于超负载或者正在进行停机维护，暂时无法处理请求，可以稍后再试。







### 响应头

响用于向客户端传递一些额外的重要信息，由字段名与字段值组成。常见的响应头包括：



|       响应头       |                             含义                             |
| :----------------: | :----------------------------------------------------------: |
|       `Date`       |   日期时间信息，表示服务器产生并发送响应报文的日期和时间。   |
|      `Server`      | 表示 HTTP 服务器应用程序的信息，类似于请求报文中的 `User-Agent` |
|     `Location`     |      此字段会配合重定向使用，用于提供重定向后新的 URL。      |
|    `Connection`    |       设置发送响应之后 TCP 连接是否继续保持的通信选项        |
|  `Cache-Control`   |                      控制缓存的相关信息                      |
|   `Content-Type`   |                     服务器返回的响应类型                     |
|  `Content-Length`  |                     服务器返回的响应长度                     |
| `Content-Encoding` |                     服务器返回的响应编码                     |
| `Content-Language` |                     服务器返回的响应语言                     |
|  `Last-Modified`   |                  指定响应内容最后的修改时间                  |
|     `Expires`      |   表示资源失效的时间，浏览器会在指定过期时间内使用本地缓存   |
|       `Etag`       |                 用于协商缓存，返回一个摘要值                 |
|  `Accept-Ranges`   |           用于断点续传，指定服务器所支持的内容范围           |
|    `Set-Cookie`    |                         设置状态信息                         |





### 响应体

响应体用于传送服务器要发给浏览器的正文。与请求报文的请求体一样，响应体可包含任意的二进制数据。



## 持久链接

客户端需要发送许多请求给服务器，如果客户端与服务器的每次请求与想要都经过一个单独的 TCP 连接发送，那么就称为 **非持续连接/短连接**；如果经过相同的 TCP 连接发送，则称为 **持续连接/长连接**。

**非持续连接**有以下几个缺点：

- 每次建立连接都需要单独经历三次握手过程，容易导致总的请求响应时间变长。即使使用并行连接，也容易加重 Web 服务器的负担。
- 建立维护多个 TCP 连接容易使得服务器存在严重负担。



HTTP/1.1 及之后的版本默认采用持续连接的方式，也可以配置为非持续连接。具体的，可以在请求头的 `Connection` 字段设置是否使用持久 ：

- 如果设置为 `Connection: Keep-Alive` 则表明此连接为持久连接（HTTP/1.1 及之后的版本默认开启）。
- 如果设置为 `Connection: Close` 则表明此连接为非持久连接，每当 TCP 连接成功发送响应数据后，就关闭连接。

需要注意，持久连接并不是永久连接，如果在一个可配置的时间间隔后，此连接仍未被使用，那么服务器将会关闭该连接。





## HTTP 缓存



对于一些短时间内不会产生变化的资源，客户端可以在请求后将服务器响应的数据资源 **缓存** 于客户端本地。当之后想要再次获取这些资源时，可以直接读取本地缓存的数据，不必再重新发送请求。

缓存的目的是 **加快响应速度**。HTTP 缓存的实现依赖于请求头于响应头的一些字段，主要分为 **强缓存** 与 **持久（协商）缓存**。



### 强缓存

**强缓存** 指的是在缓存数据未失效的情况下，将直接使用浏览器的缓存数据，不会再向服务器发送请求。



强缓存主要通过 `Cache-Control` 与 `Expires` 字段实现。

`Cache-Control` 是一个相对时间，即多长时间之后过期；`Expires` 是一个绝对时间，即在某个时间点过期。如果两个字段同时存在，前者的优先级更高。

由于服务器端时间和客户端时间可能存在偏差，因此使用 `Expires` 可能会存在时间误差，因此一般更推荐使用 `Cache-Control` 来实现强缓存。

以 `Cache-Control` 为例，强缓存的具体实现流程如下：

1. 当客户端第一次请求服务器资源时，服务器会在响应头中添加 `Cache-Control` 字段。`Cache-Control` 可以设置以下内容：

（1）`max-age=s`：表示缓存将于指定秒值后过期。如 `max-age=31536000` 表示缓存将于 31536000 秒（即 365 天）后过期；

（2）`no-store`：表示该数据不允许缓存，此字段同时适用于强缓存与协商缓存；

（3）`no-cache`：表示该数据不允许使用强缓存，只能使用协商缓存。

（4）`public`：表示该响应可以被任何对象（包括代理服务器）缓存。

（5）`private`：表示该响应只能被单个用户缓存，不能被代理服务器缓存。



2. 客户端再次向服务器请求重复资源时，根据请求资源的时间与 `Cache-Control` 中设置的过期时间大小，计算出该资源是否过期。

如果没有过期，并且可以使用缓存，那么就使用缓存，否则重新请求服务器。

![图片 1.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0ff1ec224244427ba9f15abecbd668fe~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)



### 协商缓存



**协商缓存** 指的是当第一次请求后，服务器响应头 `Cache-Control` 字段设置为 `no-cache` 或者当缓存过期后，客户端再次向服务器请求判断缓存资源是否有效。

- 如果资源没有更新，那么服务器将会返回 `304 Not Modified` 表明缓存仍然可用，就不再需要重新发送资源，同时更新缓存有效时间。
- 如果资源已更新，那么服务器将会返回 `200 OK`，并将更新后的资源放在响应体中。

![图片 2.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/56e265f46c80430fbf4673878a27bfc9~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)



协商缓存在 HTTP/1.0 与 HTTP/1.1 的实现方式有所不同。

1.  HTTP/1.0 规范

在 HTTP/1.0 中，协商缓存主要通过请求头中的 `If-Modified-Since` 与响应头中的 `Last-Modified` 字段实现。

`Last-Modified` 字段表示响应资源的最后修改时间，客户端第一次请求资源后，服务器将在响应头中携带此字段。

`If-Modified-Since` 字段是当缓存资源过期时，客户端再次发起请求并将之前接收到的 `Last-Modified` 值放在请求头 `If-Modified-Since` 中，服务器接收后，将此时间与被请求资源的实际最后修改时间进行对比：

- 如果最后修改时间不一致，说明资源已更新，那么服务器返回 `200 OK` 与已更新的资源；
- 如果最后修改时间一致，说明资源未更新，返回 `304 Not Modified`。

HTTP/1.0 规范下的协商缓存存在以下问题：

- 实现方式基于时间，但是容易因为时间误差而不可靠；
- 如果某些文件内容并未修改，只是修改了最后修改时间，那么实际上应该使用缓存但是却无法使用缓存。

2. HTTP/1.1 规范

在 HTTP/1.1 中，协商缓存主要通过请求头中的 `If-None-Match` 与响应头中的 `ETag` 字段实现。

`ETag` 字段表示相应资源的唯一标识，是一个哈希值，客户端第一次请求资源后，服务器将在响应头中携带此字段。

`If-None-Match` 字段是当缓存资源过期时，客户端再次发起请求并将之前接收到的 `ETag` 值放在请求头 `If-None-Match` 中，服务器接收后，将此哈希值与被请求资源的当前哈希值进行对比：

- 如果两者不等，说明资源已更新，那么服务器返回 `200 OK` 与已更新的资源；
- 如果两者相等，说明资源未更新，返回 `304 Not Modified`。

HTTP/1.1 规范下的协商缓存存在的问题是，服务器计算 `ETag` 哈希值会消耗系统性能。

如果 HTTP 响应头同时存在 `ETag` 与 `Last-Modified` 字段，前者优先级更高。



![图片 5.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b74c746d1459403382fd0bbc1d96aeca~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)



### 三种刷新操作对 http 缓存的影响

- 正常操作：地址栏输入 url，跳转链接，前进后退等。
- 手动刷新：f5，点击刷新按钮，右键菜单刷新。
- 强制刷新：ctrl + f5，shift+command+r。

**正常操作：强制缓存有效，协商缓存有效。** **手动刷新：强制缓存失效，协商缓存有效。** **强制刷新：强制缓存失效，协商缓存失效。**





## Cookie



一些前提知识：

- 会话

会话，指用户登录网站后的一系列动作，比如浏览商品添加到购物车并购买。

- 无状态的 HTTP 协议

在早期，HTTP协议是无状态的协议。每个 HTTP 请求都要求打开一个 TCP 连接，一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。

- 会话跟踪

会话跟踪是 Web 程序中常用的技术，用于跟踪用户的整个会话。常用的会话跟踪技术有 Cookie 与 Session。Cookie 通过在客户端记录信息确定用户身份，而 Session 通过在服务器端记录信息确定用户身份。



### 什么是 Cookie

由于 HTTP 是一种无状态的协议，因此服务器直接从网络连接了解客户端的身份。Cookie 的工作原理就是为客户端们颁发一个通行证，每个客户端都有一个独一无二的通行证（也就是 Cookie）无论哪一个客户端想要访问服务端，都必须携带属于自己的 Cookie，这样服务器就可以通过 Cookie 获知客户端的身份了。

Cookie 本质上是一小段的文本信息。当客户端向服务器发送请求时，如果服务端需要记录该用户的状态，那么在发送响应数据时就可以发送一个属于这个客户端的 Cookie。当客户端接收到响应数据后，会将 Cookie 保存起来；当客户端再次请求该服务器时，会将之前保存下的 Cookie 一同提交给服务器，服务器就可以通过 Cookie 辨认客户端状态用户状态。



### 查看 Cookie

我们可以在浏览器的开发者工具中的控制台输入 `alert(document.cookie)`，以查看该网站的 Cookie。如查看 `www.google.com` 的 Cookie：






在弹出的 Cookie 内容中，有一段字段为 `SID`，就保存了当前客户端的 Google 账号 ID。当客户端将 Cookie 协同其他数据一起发送给服务器时，服务器就可以通过 Cookie 的内容识别出当前客户端的身份。





### 不可跨域

许多网站都会使用 Cookie。例如，Google 会向客户端发送 Cookie，Baidu 也会向客户端发送 Cookie。那客户端访问 Google 时会不会也携带上 Baidu 颁发的 Cookie 呢？或者 Google 能不能修改 Baidu 颁发的 Cookie 呢？

答案是否定的。

Cookie 具有不可跨域名性。根据 Cookie 规范，浏览器访问 Google 只会携带 Google 发送的 Cookie，而不会携带 Baidu 发送的 Cookie。同理，Google 也只能操作 Google 发送的 Cookie，而不能操作 Baidu 的 Cookie。

Cookie 由客户端进行管理。客户端保证 Google 只会操作 Google 发送的 Cookie 而不会操作 Baidu 发送的 Cookie，从而保证用户的隐私安全。

客户端通过域名判断一个网站是否能操作另一个网站的 Cookie。Google 与 Baidu 的域名不一样，因此 Google 不能操作 Baidu 的 Cookie。

需要注意的是，即使是同一根域名下的不同二级域名，也无法操作彼此的 Cookie。





### 有效期



Cookie 的 `maxAge` 属性决定了 `Cookie`的有效期，单位为秒。

如果 `maxAge` 属性为正数，则表示该 Cookie 会在 `maxAge` 秒之后自动失效。浏览器会将 `maxAge` 为正数的 Cookie 写入对应的 Cookie 文件中。无论浏览器或者甚至是电脑是否关闭，只要还在 `maxAge` 秒之前，重新访问服务器时该 Cookie 仍然有效。

如果 `maxAge` 为负数，则表示该 Cookie 仅在本浏览器窗口以及本窗口打开的子窗口内有效，关闭窗口后该 Cookie 即失效。`maxAge` 为负数的 Cookie，为临时性 Cookie，不会被写到Cookie文件中。`maxAge` 为负数的 Cookie 信息直接保存在浏览器内存中，因此关闭浏览器该 Cookie 将会消失。Cookie 默认的 `maxAge` 为 –1。

如果 `maxAge` 为 0，则表示删除该 Cookie。Cookie 机制没有提供删除 Cookie 的方法，因此通过设置该 Cookie 即时失效实现删除 Cookie 的效果。失效的 Cookie 会被浏览器从 Cookie 文件或者内存中删除。









### 安全性

HTTP 协议不仅是无状态的，而且是不安全的。

使用 HTTP 协议的数据不经过任何加密就直接在网络上传播，有被截获的可能。如果不希望 Cookie 在 HTTP 等非安全协议中传输，可以设置 Cookie 的 `secure` 属性为 `true`，此时客户端只会在 HTTPS 和 SSL 等安全协议中传输此类 Cookie。



## Session



Session 是服务端记录客户端状态的机制。Cookie 保存在客户端中，Session 保存在服务端中。

Session 的核心是，当客户端访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上；客户端再次访问时服务器时，服务器只需要直接从该 Session 中查找客户端的状态即可。

当客户端第一次访问服务器时，服务器会自动创建 Session；在 Session 生成后，只要客户端继续访问，服务器就会更新 Session 的最后访问时间，并维护该 Session。



### 有效期

如果过多的 Session 存储在服务器内存中，那么会对服务器造成压力。为防止内存溢出，服务器会把长时间内没有活跃的 Session 从内存删除。这个时间就是 Session 的超时时间。如果超过了超时时间没访问过服务器，Session 就自动失效了。





### 传递

最常见使用 Session 的做法是，客户端在向服务器发送网络请求时，通过 Cookie 携带服务器分配的 SessionID。当服务器处理完对应的内容后，将数据返回给 SessionID 所对应的客户端。



### 禁用 Cookie 时

当客户端禁用 Cookie 时，我们便无法继续使用上述方法传递 Session 相关信息。通常有两种不借用 Cookie 的方式传递 Session 相关信息：

1. 重写 URL；
2. 隐藏表单字段。



重写 URL 

重写 URL 的方式是将 Session 相关信息，如 SessionID，直接以参数的形式附加在 URL 上，像这样 `www.domain.com/v1/api?sessionID=SESSIONID`。

隐藏表单字段

直接将 SessionID 附加在 URL 上存在严重的安全问题，这与直接将私密的 SessionID 暴露在网络中无疑。

隐藏表单字段的方式是通过，将 SessionID 的字段，隐藏在表单的 `hidden` 子项中，当发起网络请求时，作为参数的一部分一同发送。像下列示例一样：

```html
<form name="form"> 
	<input 
    	type="hidden" 
        name="sessionID" 
        value="ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng">
	/>
    <input
        type="text"
        name="name"
    />
    <button onclick="handleClick()"/>
</form> 
```



### Cookie 与 Session 区别



1. 数据存放上

Cookie 数据存放于客户端中，Session 数据存放于服务器中。

2. 安全性

由于私密信息直接通过 Cookie 保存在客户端本地，因此别人可以通过分析存放于本地的 Cookie 来获取隐私信息。

3. 数据大小

单个 Cookie 保存的数据不能超过 4KB，许多浏览器都限制一个站点最多保存 20 个 Cookie，因此存储的数据容易收到许多限制；而 Session 没有对存储的数据量的限制，并且可以保存更为复杂的数据类型。

4. 性能问题

Session 在一定时间内保存于服务器，当访问服务器的客户端增多时，大量的 Session 数据会占用服务器的诸多内存；当需要考虑减轻服务器性能压力时，应当考虑使用 Cookie。



# HTTP/1

主要介绍了 HTTP/1.1 的发展史，然后将介绍发展过程中遇到的各种困难以及最终的解决办法。



## HTTP/0.9

HTTP/0.9 于 1991 年提出，最初主要用于学术交流，并且需求也较为简单：用于在网络之间传递 HTML 超文本的内容，因为成为超文本传输协议。

HTTP/0.9 的实现方式也比较简单，采用了基于请求响应的模式：客户端发出请求，服务端返回数据。

HTTP/0.9 的完整请求流程如下：

1. HTTP 协议基于 TCP 协议，因此客户端需要根据 IP 地址、端口号与服务器建立 TCP 链接。
2. 建立连接后，客户端将发送一个 GET 请求行信息。

> HTTP/0.9 没有请求头与请求体，请求行也较为简单：`GET /index.html`。

1. 服务器接收到请求信息后，将会读取对应的数据，并将这些数据以 ASCII 字符流的方式返回给客户端。
2. HTML 文档传输完成后，连接断开。

当时的需求较为简单，主要是用于传输体积较小的 HTML 文件，因此 HTTP/0.9 的实现具有以下三个特点：

1. 因此此时的需求较为简单，因此只需要请求行就可以完整表达客户端的需求，所以没有 HTTP 请求头与请求体。
2. 同样，由于需求简单，服务器也没有响应头，只有响应体，也就响应的数据。
3. 由于传输的数据都是 HTML 格式的文件，因此以 ASCII 字符流传输比较合适。



## HTTP/1.0

为了能让客户端与服务器更深入地交流，HTTP/1.0 引入了请求头与响应头。

请求头与响应头都是以键值对的形式保存，在发送 HTTP 请求时，会携带上请求头的信息；同样，服务器在响应数据时，也会返回响应头信息。



### 请求头与响应头



HTTP/1.0 的方案是通过请求头与响应头来进行协商。客户端发起 HTTP 请求时，会通过请求头告知服务器它期待返回什么类型的文件、采取什么形式的压缩、提供什么语言的文件，以及文件的具体编码方式。

因而最终发出的请求头内容形式如下：

```
accept: text/html
accept-encoding: gzip, deflate, br
accept-Charset: ISO-8859-1, utf-8
accept-language: zh-CN, zh
```

`accept` 表示期望服务器返回 HTML 类型的文件。

`accept-encoding` 表示期望服务器使用 `gzip`、`deflate` 或者 `br` 中的一种方式进行压缩。

`accept-Charset` 表示期望服务器使用的文件编码方式是 `ISO-8859-1` 或 `UTF-8` 中的一种。

`accept-language` 表示期望服务器返回的内容优先语言是中文。



​	服务器在接收到客户端发送的请求头信息后，会根据请求头信息来准备响应数据。但是可能存在一些意外情况，比如客户端请求的压缩类型是 `gzip`，但是服务器并不支持 `gzip`，仅支持通过 `br` 方式压缩。那么服务器就会通过响应头的 `content-encoding` 字段告诉浏览器最终的压缩类型。因此，客户端最终需要根据响应头的信息来处理数据，下面是一段响应头的示例数据信息：

```
content-encoding: br
content-type: text/html; charset=UTF-8
```

有了响应头的信息后，浏览器就会使用 `br` 方式来解压文件，再按照 `UTF-8` 的编码格式来处理响应数据，最终按照 HTML 的方式解析文件。



HTTP/1.0 除了对多文件类型提供良好的支持外，还依据当时实际的需求引入了许多其他特性，这些特性都是通过请求头与响应头实现的：

- 有的请求服务器可能无法处理，或者处理出错，那么就需要告诉客户端处理该请求的最终情况。这就引入了 **状态码**。状态码就是通过响应行的方式来告知浏览器的。
- 为了减轻服务器的压力，HTTP/1.0 提供了 **缓存 Cache 机制**，用来缓存已经下载过的数据。
- 由于服务器需要统计客户端的基础信息，比如 Windows 与 macOS 的用户数量，因此 HTTP/1.0 的请求头还添加了 **用户代理** 的字段。





## HTTP/1.1

HTTP/1.1 在 HTTP/1.0 的基础上继续做了大量的更新。同样，我们来看 HTTP/1.0 遇到了哪些问题，以及 HTTP/1.1 的改进方案。



### 改进持久连接

HTTP/1.0 每进行一次 HTTP 通信，都需要经历建立 TCP 连接、通过 HTTP 传输数据、断开 TCP 连接三个阶段，即非持久连接。

在当时，由于通信的文件比较小，并且每个页面的引用的资源也不算多，因此这种传输形式并不存在大问题。但是随着浏览器的普及，每个页面中的图片文件越来越多，有时候一个页面可能需要包含成百上千个外部引用的资源文件。如果下载每个文件的时候，都需要建立 TCP 连接、传输数据、断开连接这样的步骤，无疑会增加大量无谓的开销。

为了解决这个问题，HTTP/1.1 增加了持久连接的方法：在一个 TCP 连接上可以传输多个 HTTP 请求。只要客户端或者浏览器没有明确断开连接，那么这个 TCP 连接就会一直保持，如果没有要发送的了，客户端最后发送 Connection:close 首部给服务器。

但是持久连接也不表示一直保持连接，是有一定时间限制的，因为如果很多主机访问同一服务器，服务器需要把他们的信息全部记录下来，这样服务器会崩溃，所以服务器不会把每个状态都记录下来，这就是 HTTP 的无状态



HTTP/1.1 持久连接可以有效减少 TCP 建立连接与断开连接的次数，从而减小了客户端与服务端双方的负担，提升了整体 HTTP 请求的有效时长。

持久连接在 HTTP/1.1 中是默认开启的，因此我们不需要专门为了持久连接取 HTTP 请求头设置信息。如果不想要使用持久连接，那么可以在 HTTP 请求头中添加 `Connection: close`。

虽然对于HTTP/1.1是持久连接，请求和响应都可以放在一个连接里面，但是一个连接肯定太慢了，连接太多又怕造成DDos攻击，因此各家浏览器允许的持久连接数都不太相同，

### 管线化

多个连接也会有问题，假设浏览器其他连接的响应文件都收到了，就剩一个连接的文件没有收到，且刚好是个会导致浏览器没法渲染的CSS文件，这也会造成HTTP对头阻塞，为了解决，HTTP/1.1有个叫 管线化 的技术，就是单个连接可以发送多个请求，但有个坑，虽然可以一次发送多个，但相应的时候必须按照发送的顺序接收，造成很大的执行难度，非常有可能第一个请求的响应丢包了，第二个响应变成了第一个接收到的。所以浏览器很少用



### 精灵图 & Data URLs

网络层面很难解决，开发层面就有黑科技，比如精灵图，把很多小图标全部做成单独一张图片，请求的时候就只需要请求一个文件，再用JS或者CSS把小图标分布到网站的各个部分，确实减少了请求次数，但是对开发者太麻烦，

除此之外，Data URLs,是另一种代替方案，可以将图片用base64编码，以字符的形式写进HTML或者CSS里面，但是编码结果很长。



### 域名分片

浏览器会限制同一连接的请求数，其实是限制每个域的连接数，因此网站就弄出多个域，使得浏览器可以同时下载这些资源，比如网站有5张图片，就可以设置5个图片域名，浏览器就可以同时下载了，也就是域名分片。



### 慢启动

TCP除了三次握手的固定开销外，还有个慢启动，因为要进行拥塞控制，为了不造成网络拥堵，因为也不知道网络的实际情况，一开始只会发送较小量的TCP数据段，后面慢慢增加，会导致新访问网页刷新速度较慢，



### 拥塞控制

TCP 的拥塞控制是一种用来调整 TCP 连接中单次发送的数据包数量（即拥塞窗口）的算法，以防止网络拥塞并确保网络传输的可靠性和公平性。它通过监控网络的状况来适应性地减少或增加拥塞窗口大小。

拥塞控制基于反馈机制，根据网络的拥堵情况向源节点动态调整发送速率。当网络负载过高时，会导致数据包的丢失、延迟和重传，从而降低网络吞吐量和可靠性。TCP 拥塞控制算法采用的方法包括：

1. 慢启动：初始时将拥塞窗口设置为一个较小的值，然后每经过一个往返时间（RTT），将拥塞窗口的大小加倍，直到出现拥塞。
2. 拥塞避免：在拥塞发生后，将拥塞窗口减半，然后进入拥塞避免状态，在拥塞窗口大小和拥塞窗口增加速率之间进行平衡。
3. 快重传和快恢复：当数据包丢失时，接收方将立即给源节点发送“冗余确认”，告诉它数据包已经到达了哪一个序号，从而避免进行重传。同时，源节点会将拥塞窗口减半，并进入快恢复状态，在未收到确认之前保持窗口大小不变，直到受到新的确认。

通过不断监控网络状态和采取适当的拥塞控制算法，TCP 能够在网络负载高时保证传输质量、减少数据丢失，从而提高网络性能和可靠性。

### HTTP本身的固定开销

除了TCP的开销，同时HTTP本身也会产生固定开销，请求和响应都是有首部的，大部分首部都是重复的，发完一次，下次还发，特别是cookie,每次都发，字符还长，1.1还是明文，首部也没有压缩，使得大部分首部累赘臃肿，就好像每次去办事对方都要你携带一大堆证明材料





# HTTP2





HTTP/1.1 为网络效率做了大量优化，最核心的有以下三点：

1. 增加了持久连接。
2. 浏览器为每个域名最多同时维护了 6 个 TCP 持久连接。
3. 使用 CDN 实现域名分片机制。

尽管 HTTP/1.1 采取了许多优化资源加载速度的策略，也取得了一定更多成果，但是 HTTP/1.1 对于带宽的利用率并不理想，这也是 HTTP/1.1 的一个核心问题。

带宽是每秒最大能发送或接收的字节数。每秒能发送的最大字节数称为上行带宽，每秒能接收的最大字节数称为下行带宽。

HTTP/1.1 对带宽利用率不理想，主要是由以下三个问题导致的：

1. TCP 慢启动

一旦一个 TCP 连接建立之后，就进入了数据发送数据阶段。在最开始的时候 TCP 协议会采用一个非常慢的速度去发送数据，然后慢慢加快发送数据的速度，直到发送数据的速度达到一个理想状态，我们把这个过程称为慢启动。

慢启动本身是 TCP 为了减少网络拥塞的一种策略，是我们没有办法改变的。

2. 同时开启多条 TCP 连接，这些连接会竞争固定的带宽

如果系统同时建立了多条 TCP 连接，当带宽充足时，每条连接的发送或者接收速度会慢慢向上增加；当带宽不足时，这些 TCP 连接又会减慢发送或者接收的速度。

这样就会出现一个问题，有的 TCP 连接下载的是一些关键资源，如 CSS、JS 文件；而有的 TCP 连接下载的是图片、视频等普通资源文件。但是多条 TCP 连接之间并不能协商让哪些关键资源优先下载，这样就可能会影响关键资源的下载速度。

3. HTTP/1.1 队头阻塞

当 HTTP/1.1 建立持久连接时，虽然只能共用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前请求没有结束之前，其他的请求只能处于阻塞状态中。这导致我们不能随意在一个管道中发送请求和接受内容。

但是阻塞请求的因素有很多，并且许多都是一些不确定的因素。一旦某一个请求被阻塞，那么后续请求在等待过程中，带宽以及 CPU 都会被白白浪费。

浏览器处理生成页面过程中，是希望能尽早接收到数据，这样就可以对这些数据做出预处理操作。但是队头阻塞使得这些数据并不能并行请求。

4. 首部不压缩

除了TCP的开销，同时HTTP本身也会产生固定开销，请求和响应都是有首部的，大部分首部都是重复的，发完一次，下次还发，特别是cookie,每次都发，字符还长，1.1还是明文，首部也没有压缩，使得大部分首部累赘臃肿，就好像每次去办事对方都要你携带一大堆证明材料



## HTTP/2 的多路复用



慢启动与 TCP 连接之间的相互竞争带宽是由于 TCP 本身的机制导致的，而队头阻塞是由于 HTTP/1.1 本身的机制导致的。

虽然 TCP 本身「有问题」，但是我们并不能直接替换 TCP，只是我们依然要想办法规避 TCP 的慢启动与竞争问题。

队头阻塞的原因是，HTTP/1.1 中需要在等待请求完成后才能去请求下一个资源，而 HTTP/2 要实现的目标就是实现资源的并行请求。



http2并不是单个文件就这样直接响应过去，请求和响应报文都被划分为各个不同的帧，这个帧可以分为首部帧和数据帧，就是把原本http报文的首部和实体给拆分为两部分，最重要的是这里有个 "流标识符"，有了这个，使得帧不用按照顺序抵达对方那里，因为就算你没有按照顺序，最终有这个流标识符就可以按照顺序进行组合，而且帧类型里还可以设置优先级，这样来标注流的权重，而且 HTTP/2 的帧并不是ASCII编码的报文，而是被提前转化为二进制的帧，解析起来更有效率，

HTTP/2 使用了多路复用技术，可以将请求分成⼀帧⼀帧的数据去传输，这样带来了⼀个额外的好处，就是当收到⼀个优先级⾼的请求时，比如接收到 JS 或者 CSS 关键资源的请求，服务器可以暂停之前的请求来优先处理关键资源的请求。



## 多路复用的实现

上一小节介绍了 HTTP/2 采取了多路复用的机制来解决 HTTP/1.1 中存在的问题，这一小节来介绍 HTTP/2 是如何实现多路复用的。

我们首先来看看 HTTP/2 的协议栈：






从图中可以看出，HTTP/2 添加了二进制分帧层。接下来我们通过梳理 HTTP/2 的请求与接收过程，来分析 HTTP/2 的多路复用是如何实现的。

1. 浏览器准备好请求数据，包括请求行、请求头等信息。
2. 这些数据经过二进制分帧层处理后，会被转换为一个个带有请求 ID 编号的帧，随后通过协议栈将这些帧发送给服务器。
3. 服务器接受完所有帧之后，会将相同 ID 的帧合并为一条完整的请求信息。
4. 随后服务器处理完整的请求信息，并将处理好的响应行、响应头和响应体分别发送至二进制分帧层。
5. 同样，二进制分帧层会将这些响应数据转换为一个个带有请求 ID 编号的帧，经过协议栈发送给浏览器。
6. 浏览器接收到响应帧后，会根据 ID 编号将帧的数据提交给对应的请求。



## HTTP/2 的其他特性

上面几个小节介绍了 HTTP/2 通过多路复用实现了资源的并行传输。而基于⼆进制分帧层，HTTP/2还附带实现了许多其他功能。

### 设置请求的优先级

浏览器中有些数据是非常重要的，但是在发送请求时，重要的请求可能会晚于那些不怎么重要的请 求，如果服务器按照请求的顺序来回复数据，那么这个重要的数据就有可能推迟很久才能送达浏览器，这对用户体验来说非常不友好。为了解决这个问题，HTTP/2 提供了请求优先级，可以在发送请求时，标上该请求的优先级，这样服务器接收到请求之后，会优先处理优先级高的请求。

### 服务器推送

当浏览器进行请求的时候，服务器可以不再像以往一样，等浏览器解析HTML时再一个一个响应，而是把浏览器后续可能需要的文件，一次性全部发送，但实际上不好操作，因为用户可能点错了网页，让浏览器一下子多了很多缓存，而且服务器推送也可能会造成DDoS非对称攻击，因为这里存在一个明显的杠杆，因此服务器推送也隐含着安全性问题，

### 头部压缩

之前1.1报文主体压缩，首部不压缩，http2这回也把首部给压缩了，这次是引入了叫 HPACK的压缩算法，该算法要求浏览器和服务器都保存一张静态只读的表，比如经典的 "HTTP/1.1 200 ok" 起始行，在HTTP/2 里就变为 ":status:200"，肉眼看只少了三个字节，但因为是重复的首部，可以实现在二次请求和相应里直接去掉，像cookie这样的首部，可以作为动态信息加入动态表里，这样就能节省可观的资源了。

HTTP/2 使用了 HPACK 算法来压缩 HTTP 头部，从而减小头部的大小。

HPACK 算法基于哈夫曼编码和上下文共享技术。它将头部字段分为两种类型：静态头部和动态头部。静态头部是指在协议中预定义的头部字段，这些头部字段的名称和值都是固定的。动态头部是指请求和响应中自定义的头部字段，这些头部字段的名称和值是可变的。

在使用 HPACK 算法对头部进行压缩时，会维护两个表：静态表和动态表。静态表中存放了预定义的头部字段，而动态表中存放了请求和响应中自定义的头部字段。

当需要发送一个头部字段时，首先会检查该字段是否已经出现过。如果该字段已经出现过，那么只需要发送该字段在静态表或动态表中的索引号。如果该字段是一个新的字段，那么需要先将该字段加入到动态表中，并将该字段在动态表中的索引号发送给对方。

HPACK 算法使用哈夫曼编码来压缩头部字段的值，从而减小头部的大小。哈夫曼编码是一种前缀编码，它将频率较高的字符编码成较短的编码，从而减小编码的长度。在 HPACK 算法中，使用了一种自适应的哈夫曼编码，它可以根据当前头部字段的值动态调整编码，从而得到更好的压缩效果。

HPACK 算法还使用了上下文共享技术，它会记录前一个请求或响应中使用的头部字段，从而在下一个请求或响应中能够更好地利用已有的头部字段信息，减小头部的大小。



客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就能提高速度了。

总的来说，HPACK 算法是 HTTP/2 头部压缩的核心算法，它能够减小头部的大小，提高协议的效率和性能。

### 安全性

但HTTP2比1.1安全很多，首先前面说的报文变成二进制的帧，对于人来说，可读性就差了很多，其次，虽然没有说HTTP/2规定要用TLS加密，但HTTP/2不用就不好了，而且浏览器都会提示不安全，而且http2的多路复用已经减少了等待时间，久而久之就变成http/2必须使用TLS



# HTTP3



http2只解决了http层面的队头阻塞，但http下面还有个传输层，而且http是基于TCP的，http2的帧下来以后就要交由TCP处理了，TCP并不知道帧里面的内容谁和谁是一起的，TCP还是按照自己的数据段发送，有丢失的，还是需要重传，所以说，即使丢失的TCP数据段刚好是一行代码的注释，也需要等待，这就是TCP层面的队头阻塞，除非让TCP也变成HTTP2的帧那样，但这样需要整个世界的操作系统革新，

核心：整合

http3把TCP和TLS1.3 的握手过程整合在一起了，

![image-20230320152844291](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230320152844291.png)

直接减少了来回带来的开销，如果是恢复会话，还可以不用握手，实现 0-RTT

但问题是TCP和TLS是两个协议，不好合并，所以只能选择传输层的UDP协议，并且在基于UDP协议上新增一个协议，QUIC

![image-20230320153036195](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230320153036195.png)



quic整合了 TPC 和 TLS ，使得HTTP3默认就是要使用加密传输的，quic是为了能够广泛部署才只能用UDP，但QUIC必须要解决TCP队头阻塞的问题，从应用层过来的数据会被封装成QUIC帧，和HTTP2的帧很像，也是加了流标识符，和HTTP2不同的是，http3的应用层上并没有所谓的帧的概念，把数据帧移到了QUIC里，相当于在传输层就有了，从源头解决队头阻塞的问题，实现多路复用，QUIC帧再次封装成QUCI数据包，上面会加上一些信息，最重要的就是加了 Connection ID 连接ID，

![image-20230320153614988](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230320153614988.png)

如果网络发生改变，如果WIFI变成流量，虽然IP地址发生改变，但是因为客户端和服务端都协商好了连接ID，因此可以用连接ID来识别为同一个连接，避免再次握手，这也是QUIC其中一个速度快的原因，QUIC数据包也会把QUIC里面的帧加密，也就是在TLS握手后，QUIC帧的内容被加密了，接着QUIC数据包会被UDP封装为数据段，UDP就会加上端口号，当我们选择HTTP3通信时，QUIC就会像TCP那样开启连接，QUIC数据包就是在这链接通道里面收发



# HTTPS



浏览器安全主要划分为三大块内容：页面安全，系统安全与网络安全，HTTPS 就属于网络安全的范畴。



最开始设计 HTTP 协议的目的比较简单，仅仅是为了传输超文本文件，因此在当时并没有太强加密传输数据的需求，HTTP 从而一直保持着明文传输数据的特征，但是明文传输会导致在传输过程中的每一个环节，数据都有可能被窃取或者篡改。

具体来说，HTTP 将数据提交给 TCP 后，数据将会经过用户电脑、WiFi 路由器、运营商，以及目标服务器等等，在这中间的每一个环节数据都有可能被窃取或者篡改。假如用户电脑被装上了恶意软件，那么恶意软件或许就有机会抓住并篡改所发出的 HTTP 请求的内容。

HTTPS 并非一个新的协议，它的原理是在 HTTP 与 TCP 两个层面中间添加了一层 **安全层 SSL/TLS**：当 HTTP 向 TCP 发送数据时，会首先经过 SSL/TLS 加密；当 TCP 接收到另外一方传过来的数据时，数据会经过 SSL/TLS 解密，再传输到 HTTP。

http请求和相应的报文都是明文的，https并不是一个单独的协议，只不过是在http的基础上使用 TLS/SSL 进行加密，这样通信就不容易收到拦截和攻击

如下图：






简单来说，安全层主要有两个职责：

1. 对发起 HTTP 请求的数据进行加密操作。
2. 对接收到 HTTP 的内容进行解密操作。

因此，我们需要了解 HTTPS 中的安全层，是如何实现加密与解密操作的。



## 使用对称加密

最简单的加密方式是使用对称加密。**对称加密指加密与解密都使用相同密钥。**

如果我们需要在客户端与服务端中加密解密同一个文件，那么我们需要提前了解加密解密的方式与对应的密钥。因此在 HTTPS 发送请求之前，浏览器和服务器之间需要协商加密的方式与密钥。

对称加密的具体方法如下：

1. 浏览器发送它所支持的加密套件列表和一个随机数 Client Random（**加密套件指的是加密的方法**，加密套件列表指的是浏览器能支持的加密方法列表）。
2. 服务器从收到的加密套件列表中选取一个加密套件，并生成一个随机数 Service Random，然后将 Service Random 与选择的加密套件返回至浏览器。
3. 浏览器和服务器分别返回确认消息。

通过上面这个步骤，服务器端与浏览器端都有了相同的 Client Random 与 Service Random，然后他们再使用相同的方法将两者混合起来生成一个密钥 Master Secret，有了密钥 Master Secret 和加密套件后，双方就可以进行数据的加密传输了。

通过这种方式，我们实现了在安全层上应用对称加密。尽管这种方式可以很好的进行工作，但是客户端与服务端所传输的 Client Random 与 Service Random 仍然是明文传输。因此理论上黑客可以得到协商好的加密套件与双方的随机数，而通过随机数合成密钥的算法是公开的，因此黑客拿到随机数之后仍然可以合成密钥，这种方式依然可以被破解。

## 使用非对称加密

使用非对称加密可以解决上面的这个问题。**非对称加密指的是有 A、B 两把密钥，如果使用密钥 A 进行加密，那么我们只能使用密钥 B 进行解密；同样，如果我们使用密钥 B 进行加密，那么只能使用密钥 A 进行解密**。

在 HTTPS 中服务器会将其中的一个密钥通过明文的形式发送给浏览器，我们把这个密钥称为 **公钥**，服务器自己留下的那个密钥叫做 **私钥**。公钥是每个人都能获取到的，而私钥只有服务器才能知道，不对任何人公开。

使用非对称加密的请求流程如下：

1. 浏览器发送加密套件列表给服务器。
2. 服务器选择一个加密套件，然后将加密套件与服务器选择好的公钥返回给浏览器。
3. 浏览器和服务器返回确认消息。

通过这种方式，浏览器端获得了服务器的公钥，那么当浏览器向服务器发送数据时，便可以使用公钥来加密数据。由于公钥加密的数据只有私钥才能解密，所以即使黑客获取了数据与公钥，也无法使用公钥来解密数据。

采用非对称加密已经可以保证浏览器发送给服务器的数据是安全的，但是这种方式仍然存在两个严重的问题：

1. 非对称加密的效率太低，这会影响到加解密数据的速度，进而影响用户打开页面的速度。
2. 无法保证服务器发送给浏览器的数据安全。虽然浏览器端可以使用公钥进行加密，但是服务器端只能使用私钥加密。私钥加密只有公钥能解密，但黑客也是可以获取到公钥的，因此不能保证服务器端的数据安全。



## 混合加密：对称加密和非对称加密搭配使用

基于以上原因，我们最终选择了一个更加完美的方案：传输数据阶段依然使用对称加密，但是对称加密的密钥我们提前采用非对称加密进行传输。



混合加密的具体流程如下：

1. 浏览器端手握一组密钥 与 ，服务器端手握非对称加密的公钥 和私钥 。
2. 浏览器端向服务器端发送加密套件列表、非对称加密套件列表。
3. 服务器端选择一个加密套件与非加密套件，并结合自己的公钥 一起返回给浏览器。
4. 浏览器使用服务器的公钥 对自己的密钥 进行加密，记加密后的密钥为 。
5. 服务器收到加密后的密钥 ，并使用自己的私钥 进行解密，得到浏览器端的密钥 。

通过这种方式浏览器端与服务器端在加密状态下，获得了浏览器端的密钥。因此在接下来传输数据的过程当中，只需要让浏览器端使用一个密钥进行加密，服务器端再使用另外一个密钥要进行解密即可。

## 数字证书

通过这种方式已经实现了数据的加密传输，但是这种方式仍然存在一个问题：假如黑客通过 DNS 劫持了目的地址的 IP 地址，并将其替换为了黑客的 IP 地址，那么我们访问的就是黑客的服务器。黑客就可以在自己的服务器上实现公钥和私钥，但是对于浏览器而言，并不知道实际上访问的是黑客的服务器。

因此服务器需要向浏览器提供证明：我就是你想访问的真正的目的地址。为了达到这一目的，服务器可以向客户端与服务端都信赖的第三方机构 **Certificate Authority CA** 申请 **数字证书 Digital Certificate**（SSL）。

浏览器也会把HTTP的默认端口80改成HTTPS的默认端口443，

数字证书由数字签名与服务器的公钥组成。因此对于浏览器而言，数字证书有两个作用：

1. 通过数字证书向浏览器证明服务器的身份。
2. 数字证书包含了服务器的公钥。

TLS1.2 就是使用的混合加密，以TLS1.2为例子讲解

正常的TCP三次握手是不变的

客户端向服务端打招呼，并把自己支持的TLS版本，加密套件发给服务端，同时还生成了一个随机数给服务端，称为第1随机数

接着服务端向客户端打招呼，服务端确认支持的TLS版本以及选择的加密套件，并且服务端也生成一个随机数发给客户端，这里称为第2随机数，接着服务端把证书和公钥发送给客户端，发送完毕了就告诉客户端发送完毕了

然后客户端这边生成随机数，称为第3随机数，预主密钥，这个预主密钥不会直接发送出去，而是用刚刚收到的公钥进行加密后再发送出去，然后客户端这边的TLS协商已经没问题了，加密开始

服务端收到加密后的预主密钥后，就用自己的私钥进行解密，这样服务器就知道预主密钥了，而且只有客户端和服务端知道这个预主密钥，除非私钥被泄露了，最后客户端用预主密钥、第1随机数、第2随机数计算出会话密钥，同时，服务端通过相同的方式计算出会话密钥，两者得到的会话密钥是相同的

也就是说，前面的步骤都是非对称加密，就是为了得到这个会话密钥，后面的会话大家都只使用这个会话密钥对数据进行加密，也就是说，后面使用的是对称加密，都使用同一个密钥

![image-20230318215537707](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230318215537707.png)

具体而言，混合加密与数字证书结合在一起的流程如下：

1. 浏览器端手握一组密钥 ，服务器端手握非对称加密的公钥 和私钥 ，CA 自己本身持有根公钥 与根私钥 ，其中根公钥 已经提前置于浏览器或操作系统。
2. 服务器向 CA 申请注册数字证书时提供自己的公钥 。CA 通过服务器的相关信息与自己的根私钥 生成数字签名，同时将服务器自己的公钥 结合在一起生成了服务器的数字证书。
3. 浏览器端想要发起请求时，首先向服务器端发送加密套件列表、非对称加密套件列表。
4. 服务器端选择一个加密套件与非加密套件，并将自己的数字证书一起返回给浏览器。
5. 浏览器端根据提前置于浏览器或者操作系统的 CA 根公钥 对数字证书进行解码，验证响应来源是对应的服务器，并获得服务器的公钥 。然后浏览器使用服务器的公钥 对自己的密钥 进行加密 。
6. 服务器收到加密后的密钥 ，并使用自己的私钥 进行解密，得到浏览器端的密钥 。

此时，浏览器与服务器已经各自持有了一组密钥，并且浏览器也已经验证了响应的数据来源是我们期待的那一个服务器，此时再数据进行加密传输即可。

通过混合加密与数字证书结合的这种方式，最终实现了数据的安全传输。

# CDN

服务器距离我们可能很远，越远的距离意味着可能要经过越多的节点，节点之间还可能出现堵塞，丢包等状况

那我们的服务器就可以备份多个服务器到世界各地，搭建的一个网络叫做 内容分发网络， Content Delivery Network 即 CDN，这个网络会有很多边缘服务器提供服务，边缘服务器就是接近用户的这些服务器，CND就是帮服务器近距离给用户分发网页内容的，  

分发内容

可以划分为 静态内容，动态内容，长期不需要改变的就是静态内容，内容经常需要改变，固定不了，就是动态内容

要注意即使是静态内容也不是一直保存在CND里面的，源服务器发送文件给CDN的时候就可以利用HTTP头部的 cache-control，可以设置相应的缓存形式，这样CDN就知道哪些支援可以保存，哪些不能，保存多久等等，

分发流程

源服务器会提前把静态内容备份给CND（push），这样世界各地的用户访问网页时，就近的CDN服务器就会把静态内容提供给用户，不需要麻烦源服务器，如果没有提前备份给CDN，CDN就得去源服务器索取相应的静态内容，也叫pull， 源服务器还可以让CDN进行备份，CDN得到内容后再分发给用户，这样其他用户同时做出请求也可以马上拿到内容了，

动态内容一般很难提供，比如说时间，不管如何，CDN的布局相当于给源服务器增加了一道墙，因为用户不再直接访问源服务器了，而必须通过CDN沟通，不再担心DDos攻击，

安全性和可靠性

不直接攻击源服务器，转而攻击CDN怎么办？可以布局多台 CDN 服务器在各个地方，监控这些CDN服务器的负载情况，如果某台服务器超载了，就会把用户那边的请求转移到没有超载的CDN服务器那边，就为了平均分配网络的流量，也叫负载均衡，怎么样转移？采用的是任播 这种技术，使用任播的通信方式，服务器对外都拥有同样一个IP地址，这个IP地址收到请求后，请求就会由距离用户最近的服务器来响应

除了这些，CDN还会采用 TLS/SSL 证书来给网站进行保护。

CDN 会帮你压缩代码



# DNS过程

浏览器首先需要看看自己的浏览器缓存有没有对应的IP记录，同时还要查询一下本地主机文件里又饿米有对应的记录，如果有记录，就没必要进行后面的步骤了

浏览器为了进行域名解析，是需要调用解析器（就是一段程序），这个解析器就相当于DNS客户端，他需要向DNS服务器查询IP地址，然后解析器就会像DNS服务器发送请求（我们电脑里就存了对应的地址），一般是最接近我们的本地DNS服务器，收到请求后，就查看自己的缓存，有就直接返回IP地址，并且标注非权威 non-authoritative， 接下来的步骤就由本地服务器完成

![image-20230318223846576](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230318223846576.png)





# DoS

指的是一台或多台机器对一个受害目标进行攻击，这一台受害目标可以是服务器、路由等等，当DoS范围足够大就形成了DDoS攻击，都是网络攻击，通过大规模的网络流量使得正常的流量不能访问受害目标，是一种压垮性的网络攻击

著名的就是SYN洪水攻击，TCP连接时仅发送SYN包，ack包不回应，对方机器就一直等待





# 握手

传输层：实现端到端的连接

套接字 socket ： IP地址+端口号



![image-20230317201816338](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230317201816338.png)



怎么样的握手才能判断出哪些请求或者哪些响应需要丢弃

TCP报文有以下标识,设置1就是开启，设置0就是关闭

SYN（Synchronization, 同步）

ACK（Acknowledgment 确认）

FIN（Finish 结束）



三次握手

客户端发送TCP报文的时候，会把该标识开启，SYN表示(Synchronization)，即同步的意思，表示客户端想和服务端进行数据的同步，同步之后，客户端和服务端就可以互相发送消息

但是仅仅发送SYN是不够的，还有一个重要的字段 Sequence 序号，应用程序可能可能连续发送多个序号给服务器，这样服务器起码就有依据可以判断哪些是累赘信息，而且这个 Sequence 序号是随机生成的，作为初始值进行后续的判断的依据，这样就保证了通道的唯一性

如果没有初始序号，客户端一下子发送两条数据，就可能会造成分歧

服务器接收到SYN后，就需要做出响应，服务器就会在TCP报文中把 SYN 和 ACK 开启，合起来就是 确认同步 的意思，同时服务器也生成自己的序号，但是不够，还需要加上 确认号，我们就使用 对方的 seq+1， 这样客户端收到号码后 -1 就知道是不是自己发送的TCP报文了，最后客户端还需要确认，不然服务器就不知道自己发送出去的 确认同步 是否被接收，所以还需要发送一次 TCP 报文来使连接正式建立，这时，客户端就会把 ACK 开启，这里的序号就用对方的 序号+1 

但是如果每次发过来的 SYN ，服务器都要记住这个序号，并且新生成自己需要记住的需要，那么服务器就需要挂起非常多的资源，如果有攻击者不断发送 SYN 又不进行下一步，就会导致服务器崩溃，就是典型的 DDos 攻击（Syn flood Syn洪流），因此服务器就直接不保存自己的序号，而是根据服务器的IP地址和端口号等私有信息进行算法的运算得到序号

![image-20230317204544736](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230317204544736.png)

建立起连接之后，就可以进行书记交流了，内容交流完毕，就可能发起关闭连接的请求，即四次挥手，客户端和服务端都能主动发起关闭请求

四次挥手

假设客户端主动发起关闭要求，，客户端就会在报文中开启 FIN 和 ACK 两个控制位，即确认结束会话，在发送HTTP请求和响应的时候，序号和确认号被不断递增，这里就不使用固定数字来表示序号和确认号

服务端就发送一个 ACK 来进行确认，自己的序号用对方的确认号，自己的确认号用对方的序号+1，虽然发送了，但此时客户端并未正式关闭通道，因为服务端可能还有需要发送的数据，

直到服务端发送完数据之后，再发送一个 FIN+ACK ，来表示最后的确认，序号和确认号不需要改变（因为没有一来一回），最后客户端得到最终的结束确认以后会发送 ACK 来进行确认，自己的序号用对方的确认号，自己的确认号用对方的序号+1



# 同源策略

在没有安全保障的 Web 网页中，我们是没有隐私的，因此需要安全策略来保障我们的隐私和数据安全。

而页面中最基础、最核心的安全策略就是 **同源策略 Same Origin Policy**。



## 同源

如果两个 URL 的协议、域名和端口号都相同，我们就称这两个 URL 同源。

浏览器默认两个同源站点可以互相访问资源并且操作 DOM 的，而两个不同源站点如果想要相互访问资源或者操作 DOM，那么就需要有一套基础的安全策略的制约，即同源策略。

同源策略主要表现在 DOM、Web 数据和网络三个层面。



## DOM

同源策略限制了来自不同源的 JavaScript 脚本对当前 DOM 对象读写的操作。

比如我们打开网页 A，并从网页 A 跳转进入网页 B：

1. 如果网页 B 与网页 A 同源，那么在网页 B 可以操控网页 A 的 DOM。
2. 如果网页 B 与网页 A 不同源，那么在网页 B 无法操控网页 A 的 DOM。



## 数据层面

同源策略限制了不同源站点读取当前站点的 Cookie、IndexDB、LocalStorage 等数据，因此无法从不同源的站点中读取其他源站点的 Cookie、IndexDB、LocalStorage 等数据。

## 网络层面

同源策略还限制了通过 `XMLHttpRequest` 等方式将站点的数据发送到不同源的站点。



## 安全性与便利性的权衡

安全性与便利性是相互对立的：直接隔离不同源站点，肯定是最安全的措施，但这也会让 Web 项目变得难以开发与使用。因此，同源策略需要在这两者之间做出权衡，即出让一部分安全性来满足便利性。

但是出让安全性又会导致许多安全问题，最典型的就是 **跨站脚本攻击 Cross Site Scripting XSS** 与 **跨站请求伪造 Cross Size Request Forgery CSRF**。



## 内容安全策略

如果同源策略限制一个页面的所有资源都来自同源，那么自然存在许多限制。因此浏览器支持引用不同源站点资源文件，但是这也导致了许多安全问题。

如果引入了恶意脚本，这些脚本就能够将页面的敏感数据比如 Cookie、IndexDB、LocalStorage 等等通过 XSS 的手段发送到指定服务器。

为了解决 XSS 攻击，浏览器中引入了 **内容安全策略 Content Safe Policy CSP**。**CSP 的核心思想是让服务器决定浏览器的脚本能够加载哪些资源，以及让服务器决定浏览器是否能够执行内联 JavaScript 代码**。

## 跨域资源共享和跨文档消息机制

默认情况下，如果打开某一个网站页面，那么该网站页面可能会通过 `XMLHttpRequest` 或者 `Fetch` 来请求其他服务器的资源。但是同源策略会阻止其向其他服务器发出请求，但是这样会很大程度制约我们的生产力。

> 注意：有三个标签是可以直接进行跨域请求的：
>
> - `<img src=xxx/>`
> - `<link href=xxx/>`
> - `<script src=xxx/>`

为了解决这个问题，便引入了 **跨域资源共享 Cross Origin Resource Sharing CORS**。CORS 可以帮助进行跨域访问控制，并且使得跨域数据传输在安全中进行。

前面提到，如果两个页面不是同源的，那么无法相互操纵 DOM。不过在实际应用中，不同源的 DOM 往往需要进行通信，因此浏览器又引入了 **跨文档消息机制**，即通过 `window.postMessage()`方法与 JavaScript 接口实现不同源之间的 DOM 通信。



# XSS 跨站脚本攻击



同源策略可以隔离不同源站点的 DOM 交互、页面数据以及网络通信。严格的同源策略会更加保证安全，但是也束缚了 Web 开发。因此需要在安全性与便捷性之间找到一个平衡点，如果浏览器默认可以引用任意第三方资源，那么就存在 XSS 风险，于是浏览器又通过 CSP 策略来加以限制。

## 什么是 XSS 攻击

**跨站脚本攻击 Cross Site Scripting** 是指黑客向 HTML 文件或者 DOM 中注入恶意脚本，从而在用户浏览页面时利用注入的恶意脚本对用户实施攻击的一种手段。跨站脚本攻击的简称为了与 CSS 进行区分，所以对齐简称为 XSS。

在早期，XSS 主要通过跨域实现，所以叫做跨域脚本。但是时至今日，向 HTML 或者 DOM 中注入恶意代码的方式越来越多，并不局限于跨域注入脚本，只是 XSS 这个名字沿用至今。

当页面被注入了恶意脚本时，浏览器无法区分这些脚本是被恶意注入的还是正常的页面内容，所以恶意注入 JavaScript 脚本也拥有所有的脚本权限，因此恶意脚本可以进行下列这些操作：

- 窃取 Cookie 信息；
- 监听用户行为；
- 修改 DOM；
- 在页面中生成浮窗广告；
- ……





## 恶意脚本是如何注入的

通常有三种方式注入恶意脚本：

1. 存储型 XSS 攻击。
2. 反射型 XSS 攻击。
3. 基于 DOM 的 XSS 攻击。

### 存储型 XSS 攻击

存储型 XSS 攻击大致需要经过下列三个步骤：

1. 黑客利用服务器漏洞将恶意脚本提交至网站服务器；
2. 用户访问了包含恶意脚本的网站；
3. 当用户浏览网站时，恶意脚本就会将用户的 Cookie 等数据上传到黑客服务器。



### 反射型 XSS 攻击

反射型 XSS 攻击与存储型 XSS 攻击类似，不同的地方在于，存储型 XSS 攻击是利用服务器将恶意脚本存储值服务器，随后返回至浏览器；而反射型 XSS 攻击是用户将恶意脚本发送至服务器，随后服务器将接收到的恶意脚本发送到网站。具体的过程如下：

1. 黑客利用网站漏洞将恶意脚本提交给服务器；
2. 服务器将恶意脚本返回至网站；
3. 恶意脚本成功在网站运行，将用户的 Cookie 等数据上传到黑客服务器。



### 基于 DOM 的 XSS 攻击

基于 DOM 的 XSS 攻击并不涉及页面的 Web 服务器。具体而言，黑客通过各种⼿段将恶意脚本注入用户页面，比如通过网络劫持在页面传输过程中修改 HTML 页面的内容。劫持类型很多，可以通过 WiFi 路由器劫持，可以通过本地恶意软件劫持……它们的共同点是在 Web 资源传输过程或者在用户使用页面的过程中修改 Web 页面的数据。





## 如何阻止 XSS 攻击

前面讲过，存储型 XSS 攻击和反射型 XSS 攻击都是需要经过 Web 服务器来处理的，因此可以认为这两种类型的漏洞是服务端的安全漏洞。

基于 DOM 的 XSS 攻击全部都是在浏览器端完成的，因此基于 DOM 的 XSS 攻击是属于前端的安全漏洞。

但无论是何种类型的 XSS 攻击，它们都有⼀个共同点，那就是首先向浏览器中注入恶意脚本，然后再通过恶意脚本将用户信息发送至黑客部署的恶意服务器上。

所以要阻止 XSS 攻击，我们可以通过阻止恶意 JavaScript 脚本的注入和恶意消息的发送来实现。

主要有以下几种方式可以实现。



### 对输入脚本进行过滤或转码

我们可以在客户端或者服务器端对关键字符进行转码，比如如果出现了脚本标签 `<script>`，那么就将其过滤掉：

```
code:<script>alert('你被 xss 攻击了')</script>
```

过滤后只留下了：

```
code:
```



### 充分利用内容安全策略 CSP

CSP 大致有如下几个功能：

- 限制加载非同源资源文件，从而即使黑客插入了恶意脚本，该脚本也无法被加载；
- 禁止向第三方提交数据，从而数据不会外泄；
- 进制执行内联脚本与未授权的脚本；
- 提供上报机制，可以帮我们尽快发现存在哪些 XSS 攻击，以便尽快修复问题。

CSP 指的是内容安全策略，它的本质是建立一个白名单，告诉浏览器哪些外部资源可以加载和执行。我们只需要配置规则，如何拦截由浏览器自己来实现。

通常有两种方式来开启 CSP，一种是设置 HTTP 首部中的 Content-Security-Policy，一种是设置 meta 标签的方式





### 使用 HttpOnly 属性



许多的 XSS 攻击都是为了盗用 Cookie，因此可以通过 `HttpOnly` 属性来保护 Cookie 的安全。

服务器可以在 HTTP 响应头中的 `Set-Cookie` 字段中使用 `HttpOnly` 标记 Cookie，这样被标记的 Cookie 只能使用在 HTTP 请求中，无法通过脚本代码来读取这段 Cookie：

```html
response.setHeader("Set-Cookie", "CookieName=value;Path=/;Domain=domainvalue;Max-Age=seconds;HTTPOnly");
```



# CSRF跨站请求伪造

**跨站请求伪造 Cross Site Request Forgery CSRF**，指引诱用户利用用户的登录状态发起跨站请求。CSRF 即利用了用户的登录状态，并通过第三方站点来进行其他操作。

攻击者可以通过一些技术手段欺骗用户的浏览器访问一个曾经认证过的网站并运行一些操作。由于浏览器曾经认证过，被访问的网站会认为是真正的用户在操作而去执行。这就是 CSRF 漏洞产生的原因：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。

​	

假设某家银行转账的 URL 形式如下：`http://domain/withdraw?account=NAME&amount=AMOUNT&to=PAYEENAME`，那么攻击者可以在另外一个网站放置这样的代码：`<img src='http://domain/withdraw?account=PETER&amount=100&to=JOHN'>`。当账户名为 Peter 的用户点击了该图片，并且此时浏览器仍然保存了 Peter 的登陆信息，那么将会自动将 100 资金转移至攻击者 John 的账户中。

类似的攻击形式有很多，并且可以藏身于许多地方。任何用户可以生成内容的地方都可能存在这种潜在的危机。因此，如果服务器没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险。

与 XSS 攻击不同的是，CSRF 攻击不需要将恶意代码注入用户的页面，仅仅是利用服务器的漏洞与用户登录状态实施攻击，并且黑客无法通过 CSRF 获取用户的页面数据。因此，XSS 攻击利用的是用户对指定网站的信任，而 CSRF 利用的是网站对用户浏览器的信任。



## 防范 CSRF 攻击

服务器防范 CSRF 攻击，通常有以下几种途径。

### 充分利用 Cookie 的 SameSite 属性

黑客主要利用用户的登陆状态进行 CSRF 攻击，而 Cookie 就是浏览器与服务器维护登陆状态的关揵数据。

CSRF 攻击通常在第三方站点发起，那么要防止 CSRF 攻击，最好能够实现 **从第三方站点发送请求时禁止 Cookie 的发送**。

即：

- 如果 HTTP 请求是同一站点发起的请求，那么就需要保证 Cookie 数据正常发送。
- 如果是从第三方站点发起请求，那么需要浏览器禁止发送某些关键 Cookie 数据到服务器。

Cookie 中的 `SameSite` 属性可以解决这个问题：在 HTTP 响应头中，通过 `Set-Cookie` 字段设置 Cookie 时，可以添加 `SameSite` 属性：

```
response.setHeader("Set-Cookie", "CookieName=value;Path=/;Domain=domainvalue;SameSite=Strict");
```

`SameSite` 属性通常有 `Strict`、`Lax` 和 `None` 三个选项：

- `Strict`：最为严格。浏览器会完全禁止第三方 Cookie；
- `Lax`：相对宽松。在跨站点的情况下，从第三方站点发送请求或者从第三方站点提交 `GET` 表单都会携带 Cookie。但是如果在第三方站点使用 `POST` 方法，或者通过 `<img>`、`<iframe>` 等标签加载 URL 都不会携带 Cookie；
- `None`：宽松。对于发送 Cookie 没有任何限制。



### 验证请求的来源站点

服务器通过请求头的 `Referer` 与 `Origin` 字段判断来源站点。

`Referer` 记录了该 HTTP 请求的来源地址。虽然可以通过 `Referer` 字段告诉服务器 HTTP 请求的来源，但是有一些场景并不适合将来源 URL 暴露给服务器。因此可以不用上传 `Referer` 字段。

`Origin` 记录了该 HTTP 请求的源信息（协议、域名与端口号），并不包括完整的 URL 路径。

服务器的策略是优先判断 `Origin` 属性，如果请求头中没有包含 `Origin` 属性，那么再根据实际情况来判断是否使用 `Referer` 值。





### Token

另外一种方式是，服务器与浏览器约定一个独立于登陆状态以外的隐藏值作为 Token。当网站向服务器发起请求时，服务器生成一个 CSRF Token 返回至网站站点并进行隐藏；当该网站站点再次向服务器发起请求时，需要携带本站点中隐藏的 CSRF Token 值。





# 跨域的解决方案





## CROS



**跨域资源共享 Cross Origin Resource Sharing CORS** 是浏览器引入的解决跨域的一个方案。CORS 可以帮助我们进行跨域访问控制，并使得我们的跨域数据传输在安全中进行。

要注意的一个细节是：我们的请求跨域了，那么我们的请求到底有没有发出去？

答案是：跨域并不是请求发不出去，而是请求正常发送，服务端收到请求返回正常结果，只是结果被浏览器拦截了。



CORS 允许浏览器向跨源服务器发送 `XMLHttpRequest` 请求，从而克服了 AJAX 只能同源使用的限制。但是 CORS 需要浏览器和服务器同时支持，浏览器一旦发现跨域请求，就会添加一些附加的头信息。

浏览器将 CORS 请求分为两类：简单请求与复杂请求。

### 简单请求

简单请求不会触发预检。请求如果满足下列几个条件，都属于简单请求，否则属于非简单请求：

- 请求方法是以下三种方法之一：
  - `HEAD`
  - `GET`
  - `POST`
- 没有人为设置以下几种字段外的请求头：
  - `Accept`
  - `Accept-Language`
  - `Content-Language`
  - `Content-Type` 只限于三个值：`application/x-www-form-urlencoded`、`multipart/form-data`、`text/plain`。
  - `DPR`
  - `Downlink`
  - `Save-Data`
  - `Viewport-Width`
  - `Width`
- 请求中的 `XMLHttpRequestUpload` 对象没有注册事件监听器。
- 请求中没有使用 `ReadableStream` 对象。

浏览器会为简单请求的请求头添加 `Origin` 字段，描述请求来源的源信息：协议、域名与端口号。

请求发送至服务器后，服务器如果认为该请求可接收，会在响应头 `Access-Control-Allow-Origin` 字段中指定相同的源信息或者使用 `*` 表示所有域名。

除此之外，响应头中可能包括 `Access-Control-Expose-Headers` 字段。由于 `XMLHttpRequest` 对象方法只能够拿到响应头的这六个字段：`Cache-Control`、`Content-Language`、`Content-Type`、`Expires`、`Last-Modified` 与 `Pragma`。如果 `XMLHttpRequest` 对象想要获取其他字段，服务器可以将其他字段填入 `Access-Control-Expose-Headers` 字段。

### 复杂请求

在 CORS 策略下，复杂请求会在正式通信之前进行一次 **预检** 请求。

浏览器会先询问服务器，当前网页所在的域名是否可以请求该服务器，以及可以使用哪些 HTTP 请求头，只有得到了肯定的答复之后，才会进行正式的请求。

**预检** 请求的方法是 `OPTIONS`，表示该请求用于询问。

服务器在收到预检请求并检查 `Origin`、`Access-Control-Request-Method` 与 `Access-Control-Request-Headers` 字段后，将对其做出响应。

- 如果服务器拒绝了本次预检请求，那么在返回正常 HTTP 响应报文中，HTTP 响应头将不会含有任何与 CORS 相关的头信息。
- 如果服务器同意了本次预检请求，就会在 HTTP 响应头中添加 `Access-Control-Allow-Origin` 等字段。同时浏览器在确定服务器同意预检后，将会发出正式的 HTTP 跨域请求。

## JSONP

**JSONP JSON with Padding** 实现跨域的原理是 **利用脚本标签 `<script>` 不受跨域限制的漏洞，使得网页可以从其他来源中接收 JSON 数据**。

尽管都是客户端像浏览器发送请求获取数据，但是 AJAX 受同源策略的影响，而 JSONP 不受影响，可以发起跨域请求。

JSONP 的优点是简单兼容性好，但是缺点也十分明显：仅支持 `GET` 方法，并且容易遭受 XSS攻击。



## 具体实现流程

1. 定义一个辅助函数，接收请求的接口地址、参数，与一个方法名如 `work`：

```
function jsonp({url, params, callback}) {}
```

1. 辅助函数返回 `Promise` 实例对象，并将接口与参数整合为请求的 URL，并在 DOM 中添加 `script` 节点，指定该 URL 为 `script` 节点的 `src` 属性：

```js
function jsonp({url, params, callback}) {
    return new Promise((resolve) => {
        const script = document.createElement('script')
        const arrs = []
        for (const key in params) {
            arrs.push(`${key}=${params[key]}`)
        }
        arrs.push(`callback=${callback}`)
        script.src = `${url}?${arrs.join('&')}`
        document.body.appendChild(script)
    })
}
```



3. 在全局对象（浏览器中为 `window`）定义传入的方法名，将其作为最后执行的方法。在这个方法中，首先要通过 `resolve()` 改变 `Promise` 实例的状态，还需要移除已经执行结束的脚本：

```js
function jsonp({url, params, callback}) {
    return new Promise((resolve) => {
        const script = document.createElement('script')
        window[callback] = function (data) {
            resolve(data)
            document.body.removeChild(script)
        }
        const arrs = []
        for (const key in params) {
            arrs.push(`${key}=${params[key]}`)
        }
        arrs.push(`callback=${callback}`)
        script.src = `${url}?${arrs.join('&')}`
        document.body.appendChild(script)
    })
}

// 调用
jsonp({
    url: 'http://localhost:3000/api',
    params: {
        name: 'Yucohny'
    },
    callback: 'work'
}).then(data => {
    console.log(data)
})
```

4. 在服务器代码中，将该接口的对应的属性值取出，并将其作为字符串形式函数调用的方法名，如 `work(age=20)`。当字符串形式的函数调用返回至浏览器后，浏览器将自动识别并查找 `window` 中是否有对应的方法名，如果有就调用：

```js
const http = require('http')
const url = require('url')

http.createServer(function (req, res) {
    const callback = url.parse(req.url, true).query.callback
    res.write(`${callback}(age=20)`)
    res.end()
}).listen(3000)
```

## Window.postMessage()

`window.postMessage()` 方法可以安全地实现跨域通信。`window.postMessage()` 方法提供了一种机制来规避同源策略的限制：

如果满足下列三者中的一种，那么可以通过 `window.postMessage()` 方法实现跨域通信：

1.页面与其打开的新窗口的数据传递；

2.多窗口之间数据传递；

3.页面与嵌套的 iframe 消息传递。

方法参数如下：

```
otherWindow.postMessage(message, targetOrigin, [transfer])
```

- `otherWindow`：其他窗口的引用，比如 `iframe` 的 `contentWindow` 属性；
- `message`：发送的数据；
- `targetOrigin`：目标地址，指定哪些窗口能接收到数据；
- `transfer`：可选参数，一串与数据同时传递的 `Transferable` 对象。这些对象的所有权将被转移至消息的接收方，发送方不再具有所有权。

例如

我在8000端口，放了一份a.html，内容如下

```html
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Page A</title>
</head>

<body>
    <h1>Page A</h1>
    <script>
        const targetWindow = window.open('http://localhost:8080/b.html')
        let a = document.querySelector('h1')
        a.onclick = function () {
            targetWindow.postMessage('Hello from a.html!', 'http://localhost:8080')
        }



    </script>
</body>

</html>
```

我在8080端口放置了一份b.html

```html
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Page B</title>
</head>

<body>
    <h1>Page B</h1>
    <script>

        window.addEventListener('message', event => {
            if (event.origin === 'http://localhost:8000') {
                console.log(`Received message from ${event.origin}: ${event.data}`)
            }
        });
    </script>
</body>

</html>
```



当我点击标题A，他就会向 8080端口得b.html页面发送消息

而b.html通过 message 事件监听了来自 8000 的消息，于是我们能在b.html的控制台看到内容如下

![image-20230320211257665](C:\Users\zzzzp\AppData\Roaming\Typora\typora-user-images\image-20230320211257665.png)

## WebSocket

**WebSocket** 实现了浏览器与服务器的全双工通信，同时也是跨域的一种解决方案。WebSocket 与 HTTP 都是应用层协议，也都基于 TCP 协议。但是 WebSocket 是一种双向通信协议，在建立持久连接之后，服务器与客户端都能主动向对方发送或接收数据。

浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接， 并进行双向数据传输。

例如

我们可以在一个js 文件中，添加以下代码，注意我们需要先下载 `ws`包

```js
const WebSocket = require('ws');

const wss = new WebSocket.Server({ port: 8080 });

wss.on('connection', function connection(ws) {
  console.log('Client connected');

  ws.on('message', function incoming(message) {
    console.log(`Received message: ${message}`);
    ws.send(`Echo: ${message}`);
  });

  ws.on('close', function() {
    console.log('Client disconnected');
  });
});

```

随后我们可以在一个hmtl文件中添加以下代码

```html
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>

<body>
    <script>
        const ws = new WebSocket('ws://localhost:8080')

        ws.addEventListener('open', function (event) {
            console.log('Connected to WebSocket server')

            ws.send('Hello from client!')
        })

        ws.addEventListener('message', function (event) {
            console.log(`Received message: ${event.data}`)
        })

        ws.addEventListener('close', function (event) {
            console.log('Disconnected from WebSocket server')
        })

    </script>
</body>

</html>
```

这样，我们打开服务器和这个html文件，两者就会产生关联，并打印相应语句

## nginx 反向代理

nginx 是常见的 Web 服务器，可以作为中间件转发请求。

nginx 可以通过反向代理实现跨域，只需要进行简单的配置。





# 进程与线程



- 进程：一个进程是一个程序的运行实例
- 线程：线程是操作系统中能够进行运算调度的最小单位



* 单线程：当有多个任务要分开执行时，由于单线程只有一个运算单位，因此这多个任务只能挨个执行，即串行执行
* 多线程：如果这里的多个任务相互独立，那么我们可以用若干个单线程（也就是多线程）来分配任务的执行，即使用多线程同时执行，即并行执行
* 多进程：一个操作系统同时运行多个应用程序、一个浏览器同时打开多个tab页面

## 线程与进程

线程依托于进程，由进程来启动和管理。

当我们启动⼀个程序的时候，操作系统会为该程序创建⼀块内存，用来存放代码、运行数据和⼀个执行任务的主线程，这里的运行环境就叫做进程。

线程与进程有下列四个特点：

1. 进程中的任意线程执行出错，都会导致整个进程的崩溃。
2. 线程之间能够共享进程中的数据。
3. 当⼀个进程关闭之后，操作系统会回收进程所占用的内存。
4. 进程之间的内容相互隔离。



## 当前 Chrome 架构

包含了 5 个**进程**

- 浏览器主进程（一个），浏览器tab切换、回退刷新等操作
- 网络进程，负责网络资源加载（一个）
- GPU进程（一个），负责像素点绘制
- 插件进程（一个插件一个）
- 渲染进程（一个tab一个），多个tab互不影响

**线程**

GUI渲染线程

- 负责解析HTML、CSS构建DOM数和 render树
- 时间：重绘、回流时会执行
- 特点：与JS引擎互斥

JavaScript引擎线程

- 作用：处理JS脚本程序，编译JS代码，如V8引擎，Chrome和Node.js都在用
- 起因：JS语言是一门单线程语言，它的异步和多线程是通过Event Loop事件循环来实现的
- 特点：与GUI引擎互斥
- 构成：内存堆（内存分配）、调用栈（代码执行）
- 由于是单线程，通过事件循环机制来实现异步任务

事件触发线程

- 控制事件循环的节奏，当执行栈（js主线程执行完空闲后），从消息队列中取出一个任务放入执行栈中执行
- 执行栈为空后，再从消息队列中取出一个放入执行栈中执行
- 维护一个消息队列

定时器触发线程

- setTimeout、setInterval

异步请求线程

- 发送网络请求获取数据





## 线程的生命周期与状态

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/301fba6563994d7e9a6d72bb12bad65b~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

1. new 新建 创建线程对象这个阶段
2. ready 就绪  线程正在等待使用CPU，经调度程序调用之后可进入running状态。

3. running 运行  线程正在使用CPU。
4. waiting阻塞 线程经过等待事件的调用或者正在等待其他资源（如I/O）。
5. **Terminated状态** 当一个线程进入到Terminated状态后，就代表它的生命周期已经结束



## 死锁与解决

多个线程同时被阻塞，它们中的⼀个或者全部都在等待某个资源被释放

产生死锁必须满足四个条件：

1. 互斥条件：该资源任意⼀个时刻只由⼀个线程占⽤。
2. 请求与保持条件：⼀个进程因请求资源⽽阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在末使⽤完之前不能被其他线程强⾏剥夺，只有⾃⼰使⽤完毕后才释放资源。
4. 循环等待条件:若⼲进程之间形成⼀种头尾相接的循环等待资源关系。

避免死锁

1. 破坏请求与保持条件 ：⼀次性申请所有的资源。
2. 破坏不剥夺条件 ：占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。



# 登录





## Cookie + Session 登录

HTTP 是一种无状态的协议，客户端每次发送请求时，首先要和服务器端建立一个连接，在请求完成后又会断开这个连接。这种方式可以节省传输时占用的连接资源，但同时也存在一个问题：***每次请求都是独立的***，服务器端无法判断本次请求和上一次请求是否来自同一个用户，进而也就无法判断用户的登录状态。



> Cookie: 是服务器端发送给客户端的一段特殊信息，这些信息以文本的方式存放在客户端，客户端每次向服务器端发送请求时都会带上这些特殊信息。



有了 Cookie 之后，服务器端就能够获取到客户端传递过来的信息了，如果需要对信息进行验证，还需要通过 Session。

> 客户端请求服务端，服务端会为这次请求开辟一块内存空间，这个便是 Session 对象。

有了 Cookie 和 Session 之后，我们就可以进行登录认证了。



### 实现流程

用户首次登录时：

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/2/1730fcc51a6e8670~tplv-t2oaga2asx-zoom-in-crop-mark:4536:0:0:0.image)

1. 用户访问 `a.com/pageA`，并输入密码登录。
2. 服务器验证密码无误后，会创建 SessionId，并将它保存起来。
3. 服务器端响应这个 HTTP 请求，并通过 Set-Cookie 头信息，将 SessionId 写入 Cookie 中。

> 服务器端的 SessionId 可能存放在很多地方，例如：内存、文件、数据库等。

第一次登录完成之后，后续的访问就可以直接使用 Cookie 进行身份验证了：

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/2/1730fcc51a81b9f8~tplv-t2oaga2asx-zoom-in-crop-mark:4536:0:0:0.image)

1. 用户访问 `a.com/pageB` 页面时，会自动带上第一次登录时写入的 Cookie。
2. 服务器端比对 Cookie 中的 SessionId 和保存在服务器端的 SessionId 是否一致。
3. 如果一致，则身份验证成功。





### Cookie + Session  存在的问题

虽然我们使用 Cookie + Session  的方式完成了登录验证，但仍然存在一些问题：

- 由于服务器端需要对接大量的客户端，也就需要存放大量的 SessionId，这样会导致服务器压力过大。
- 如果服务器端是一个集群，为了同步登录态，需要将 SessionId 同步到每一台机器上，无形中增加了服务器端维护成本。
- 由于 SessionId 存放在 Cookie 中，所以无法避免 CSRF 攻击。



## Token 登录





Token 是服务端生成的一串字符串，以作为客户端请求的一个令牌。当第一次登录后，服务器会生成一个 Token 并返回给客户端，客户端后续访问时，只需带上这个 Token 即可完成身份认证。

### Token 机制实现流程

用户首次登录时：

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/2/1730fcc51ab8a1db~tplv-t2oaga2asx-zoom-in-crop-mark:4536:0:0:0.image)

1. 用户输入账号密码，并点击登录。
2. 服务器端验证账号密码无误，创建 Token。
3. 服务器端将 Token 返回给客户端，由**客户端自由保存**。



后续页面访问时：

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/2/1730fcc519ee3add~tplv-t2oaga2asx-zoom-in-crop-mark:4536:0:0:0.image)

1. 用户访问 `a.com/pageB` 时，带上第一次登录时获取的 Token。
2. 服务器端验证 Token ，有效则身份验证成功。



### Token 机制的特点

根据上面的案例，我们可以分析出 Token 的优缺点：

- 服务器端不需要存放 Token，所以不会对服务器端造成压力，即使是服务器集群，也不需要增加维护成本。
- Token 可以存放在前端任何地方，可以不用保存在 Cookie 中，提升了页面的安全性。
- Token 下发之后，只要在生效时间之内，就一直有效，如果服务器端想收回此 Token 的权限，并不容易。



### Token 的生成方式



最常用的 Token 生成方式是使用 JWT(Json Web Token)

上文中我们说到，使用 Token 后，服务器端并不会存储 Token，那怎么判断客户端发过来的 Token 是合法有效的呢？

答案其实就在 Token 字符串中，其实 Token 并不是一串杂乱无章的字符串，而是通过多种算法拼接组合而成的字符串，我们来具体分析一下。

JWT 算法主要分为 3 个部分：header（头信息），payload（消息体），signature（签名）。





# SSO 单点登录

单点登录指的是在公司内部搭建一个公共的认证中心，公司下的所有产品的登录都可以在认证中心里完成，一个产品在认证中心登录后，再去访问另一个产品，可以不用再次登录，即可获取登录状态。





# OAuth 第三方登录



在上文中，我们使用单点登录完成了多产品的登录态共享，但都是建立在一套统一的认证中心下，对于一些小型企业，未免太麻烦，有没有一种登录能够做到开箱即用？

其实是有的，很多大厂都会提供自己的第三方登录服务，我们一起来分析一下。



### OAuth 机制实现流程

这里以微信开放平台的接入流程为例：

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/2/1730fcc5628c0462~tplv-t2oaga2asx-zoom-in-crop-mark:4536:0:0:0.image)

1. 首先，`a.com` 的运营者需要在微信开放平台注册账号，并向微信申请使用微信登录功能。
2. 申请成功后，得到申请的 appid、appsecret。
3. 用户在 `a.com` 上选择使用微信登录。
4. 这时会跳转微信的 OAuth 授权登录，并带上 `a.com` 的回调地址。
5. 用户输入微信账号和密码，登录成功后，需要选择具体的授权范围，如：授权用户的头像、昵称等。
6. 授权之后，微信会根据拉起 `a.com?code=123` ，这时带上了一个临时票据 code。
7. 获取 code 之后， `a.com` 会拿着 code 、appid、appsecret，向微信服务器申请 token，验证成功后，微信会下发一个 token。
8. 有了 token 之后， `a.com` 就可以凭借 token 拿到对应的微信用户头像，用户昵称等信息了。
9. `a.com` 提示用户登录成功，并将登录状态写入 Cooke，以作为后续访问的凭证。



